{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sambhavpurohit14/Smart_Gallery/blob/text-encoder-trials/text_embeddings.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel\n",
        "import torch\n",
        "import gensim.downloader as api"
      ],
      "metadata": {
        "id": "uAZ_UXxvYGQa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_caption_embeddings(caption, model_type):\n",
        "    \"\"\"\n",
        "    Generate a mean word embedding for the caption using the specified model.\n",
        "    \"\"\"\n",
        "    if model_type == 'cbow':\n",
        "        cbow_model = api.load('word2vec-google-news-300')\n",
        "\n",
        "        words = caption.split()\n",
        "        # get embeddings for words in the vocabulary\n",
        "        embeddings = [cbow_model[word] for word in words if word in cbow_model]\n",
        "        if embeddings:\n",
        "            # return mean embedding\n",
        "            return np.mean(embeddings, axis=0)\n",
        "        else:\n",
        "            return np.zeros(cbow_model.vector_size)\n",
        "\n",
        "    '''\n",
        "    tokenizer outputs token ids and attention mask\n",
        "    returns as tensor\n",
        "\n",
        "    bert model : input tokenized inputs, outputs last hidden state\n",
        "    apply attention mask on the inputs - identifies word and padding\n",
        "\n",
        "    '''\n",
        "\n",
        "    if model_type == 'bert':\n",
        "        model_name = \"bert-base-uncased\"\n",
        "        tokenizer = BertTokenizer.from_pretrained(model_name)\n",
        "        bert_model = BertModel.from_pretrained(model_name)\n",
        "        sentences = [caption]\n",
        "        inputs = tokenizer(sentences, padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "        with torch.no_grad():\n",
        "            outputs = bert_model(**inputs)\n",
        "            token_embeddings = outputs.last_hidden_state\n",
        "\n",
        "        attention_mask = inputs[\"attention_mask\"]\n",
        "        attention_mask = attention_mask.unsqueeze(-1)  #match shape of token embeddings\n",
        "        '''dimnension : [batch_size, sequence_length, 1]\n",
        "        compatible for element-wise multiplication of token embeddings and attention mask, doesnt add any new data (?)\n",
        "        '''\n",
        "        sentence_embeddings = torch.sum(token_embeddings * attention_mask, dim=1) / torch.sum(attention_mask, dim=1) #weighted average\n",
        "\n",
        "        return sentence_embeddings.numpy()\n"
      ],
      "metadata": {
        "id": "hUo0bsx8H6I1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#call function\n",
        "encoder_type = input(\"Enter the encoder type (cbow/bert): \")\n",
        "sentence = input(\"Enter the sentence: \")\n",
        "print(get_caption_embeddings(sentence, encoder_type))"
      ],
      "metadata": {
        "id": "4vvtbGOIduLS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(get_caption_embeddings( 'he discovered a map that will lead him to the treasure island' , 'cbow'))"
      ],
      "metadata": {
        "id": "EbvgjtlJ0FKN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "10e4ca70-c21e-4de4-943e-1908feba6eae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[ 0.0793457   0.07609864  0.07420655  0.04150391 -0.02399292 -0.0560791\n",
            " -0.04064331 -0.13105468  0.06124573  0.09473877  0.04650269 -0.13260803\n",
            "  0.01254272 -0.02023926 -0.1161438   0.04530334 -0.0320221   0.14226075\n",
            "  0.02257233  0.01842651  0.02873173  0.00661621  0.01523438  0.05429916\n",
            "  0.04060059 -0.00440369 -0.07633056  0.01339111  0.04108734 -0.01483154\n",
            "  0.01257324  0.01239624 -0.05804443  0.01967621  0.02949219 -0.06587219\n",
            "  0.05095215 -0.02755127  0.07716064  0.0607544   0.06325684 -0.00527649\n",
            "  0.11011963 -0.03266602 -0.02029419 -0.06052704 -0.06203613  0.01164856\n",
            "  0.02537842  0.00384521  0.04329834  0.07330932  0.02456665 -0.08997802\n",
            " -0.0588501   0.03557129 -0.0566864  -0.16756591  0.05548554 -0.01115417\n",
            "  0.08276768  0.09409697 -0.02213135 -0.01397095 -0.0727417  -0.02767944\n",
            " -0.00895996  0.02041016 -0.01472473  0.02885437  0.05957031 -0.0090477\n",
            "  0.0791565  -0.04113159 -0.13609314 -0.04261475  0.07692871  0.07792969\n",
            "  0.06124268  0.03267212  0.05451507 -0.07513428  0.05440063 -0.05668945\n",
            " -0.047229   -0.03263855 -0.05053711  0.02115479  0.0206543   0.03945923\n",
            "  0.01472168 -0.04302979  0.0083786  -0.11358567 -0.0041748   0.00355453\n",
            "  0.01239319  0.02070618  0.0609436  -0.03374023 -0.06055164 -0.01955872\n",
            "  0.06906128  0.00023193 -0.00648422 -0.03289185 -0.03477783 -0.11523743\n",
            "  0.01030579 -0.05243378 -0.0607666   0.04817505  0.01176758 -0.03181458\n",
            "  0.06816788  0.00058594 -0.02048054 -0.03702583  0.11068115  0.04212647\n",
            " -0.08149414 -0.03083496 -0.07302399  0.08025207 -0.087323   -0.01052704\n",
            "  0.02700501 -0.10875473 -0.07542114  0.10033569 -0.01257935 -0.04364624\n",
            " -0.12348328  0.05151367 -0.01903686 -0.06357422 -0.00510254 -0.00393066\n",
            "  0.00531006  0.11879883 -0.07857056 -0.06343994  0.00623169  0.03862\n",
            "  0.0472992   0.02308502 -0.06047363 -0.06341247 -0.07992554  0.04547119\n",
            "  0.02066956  0.05240478 -0.10019531  0.07537842  0.03466339  0.00190735\n",
            " -0.04436035 -0.07270508 -0.04521484  0.01586914  0.00432739  0.07622071\n",
            "  0.10980835 -0.00375366 -0.01981506 -0.02887573  0.11218262 -0.04186859\n",
            " -0.02206364 -0.02915039  0.03242188  0.05292969 -0.02530518 -0.05593262\n",
            " -0.01001587 -0.0260498  -0.00983887 -0.0809082   0.02489624  0.00313721\n",
            " -0.13955078 -0.02089844 -0.00922852  0.02518311 -0.07837524 -0.0012146\n",
            " -0.01451378  0.02320251  0.18361816  0.02785644  0.04718018  0.00897903\n",
            "  0.04462662  0.07562256 -0.09458618  0.03190918 -0.04098511  0.02827911\n",
            " -0.08269043 -0.18867187  0.00107422  0.01612091 -0.04053049 -0.07621231\n",
            "  0.03222656  0.0552002  -0.01378174 -0.01368408  0.0640831  -0.0559269\n",
            " -0.02540283  0.01610718 -0.08476563  0.01034851 -0.08120117  0.02765961\n",
            "  0.11872558 -0.04555664 -0.07767944  0.00893402  0.07551269 -0.04780274\n",
            " -0.02612915 -0.06558838  0.01116943 -0.06760406  0.07020263  0.08725586\n",
            "  0.01711731  0.02668152  0.04761658 -0.10303345 -0.06404419 -0.06013184\n",
            "  0.09359817 -0.02338867 -0.01657715  0.02449341  0.15477295  0.00518494\n",
            "  0.0247345  -0.10358886  0.03293457 -0.08506928  0.02312164  0.04029541\n",
            "  0.10878296  0.02789307  0.10854797 -0.01795654 -0.04333496 -0.0439209\n",
            "  0.00579834  0.03967543  0.00971069 -0.0484314   0.0414154  -0.08793946\n",
            " -0.11705132 -0.10230713  0.02711182 -0.03318787 -0.06914673  0.05911102\n",
            "  0.08222656  0.0665039  -0.04517822 -0.01762085 -0.02306824 -0.05428772\n",
            "  0.1126709   0.02215185  0.00865479  0.06362305  0.01107178 -0.02504272\n",
            " -0.00233154 -0.11778565 -0.0768013  -0.03406982  0.01322022 -0.00992279\n",
            "  0.05748902  0.04157715  0.02694702 -0.08291626 -0.1059433   0.05751343\n",
            "  0.03043823 -0.0006897  -0.06910668 -0.01347313 -0.11961059 -0.04636841\n",
            " -0.04854736 -0.03267212 -0.05368958 -0.10423584  0.08665161 -0.07255249]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT\n",
        "\n",
        "-2.97022969e-01 -3.45540017e-01  1.59468085e-01  1.29468590e-01\n",
        "   4.95176822e-01 -1.65851742e-01  1.96444586e-01  3.67893666e-01\n",
        "   6.09932616e-02 -2.23868951e-01 -6.20057061e-02 -7.82726109e-01\n",
        "   1.73034549e-01  7.72786558e-01 -2.23108456e-01 -1.04516871e-01\n",
        "\n",
        "\n",
        "-------------\n",
        "CBOW\n",
        "\n",
        "0.0793457   0.07609864  0.07420655  0.04150391 -0.02399292 -0.0560791\n",
        " -0.04064331 -0.13105468  0.06124573  0.09473877  0.04650269 -0.13260803\n",
        "  0.01254272 -0.02023926 -0.1161438   0.04530334 -0.0320221   0.14226075\n",
        "  "
      ],
      "metadata": {
        "id": "gBvXz1JXbCao"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "authorship_tag": "ABX9TyPc1xR5KaieOn6+D1LzRkAo",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}