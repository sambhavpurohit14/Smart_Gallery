{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":219308226,"sourceType":"kernelVersion"}],"dockerImageVersionId":30839,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import datasets, transforms, models\nfrom torchvision import transforms\nfrom torch.nn.functional import normalize\nfrom torchvision.models import resnet50, ResNet50_Weights\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:54:59.196976Z","iopub.execute_input":"2025-01-26T11:54:59.197408Z","iopub.status.idle":"2025-01-26T11:54:59.203173Z","shell.execute_reply.started":"2025-01-26T11:54:59.197376Z","shell.execute_reply":"2025-01-26T11:54:59.201878Z"}},"outputs":[],"execution_count":133},{"cell_type":"code","source":"# class ProjectionHead(nn.Module):\n#     def __init__(self, input_dim, hidden_dim, output_dim):\n#         super(ProjectionHead, self).__init__()\n#         self.fc1 = nn.Linear(input_dim, hidden_dim)\n#         self.fc2 = nn.Linear(hidden_dim, output_dim)\n#         self.relu = nn.ReLU()\n#         self.bn = nn.BatchNorm1d(hidden_dim)\n\n#     def forward(self, x):\n#         x = self.fc1(x)\n#         x = self.bn(x)\n#         x = self.relu(x)\n#         x = self.fc2(x)\n#         return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:54:59.204454Z","iopub.execute_input":"2025-01-26T11:54:59.204748Z","iopub.status.idle":"2025-01-26T11:54:59.221506Z","shell.execute_reply.started":"2025-01-26T11:54:59.204723Z","shell.execute_reply":"2025-01-26T11:54:59.220455Z"}},"outputs":[],"execution_count":134},{"cell_type":"code","source":"\nclass ProjectionHead(nn.Module):\n    def __init__(self, input_dim=2048, hidden_dim=512, output_dim=128, dropout_rate=0.1):\n   \n        super(ProjectionHead, self).__init__()\n        \n        # Define the layers\n        self.fc1 = nn.Linear(input_dim, hidden_dim)\n        self.bn1 = nn.BatchNorm1d(hidden_dim)\n        self.relu = nn.ReLU(inplace=True)\n        self.dropout = nn.Dropout(dropout_rate)\n        \n        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n        self.bn2 = nn.BatchNorm1d(hidden_dim)\n        \n        self.fc3 = nn.Linear(hidden_dim, output_dim)\n        \n    def forward(self, x):\n     \n        # First layer\n        x = self.fc1(x)\n        x = self.bn1(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        # Second layer\n        x = self.fc2(x)\n        x = self.bn2(x)\n        x = self.relu(x)\n        x = self.dropout(x)\n        \n        # Third layer \n        x = self.fc3(x)\n        \n        # Normalize the output embeddings to lie on a unit hypersphere\n        x = nn.functional.normalize(x, p=2, dim=1)\n        \n        return x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:54:59.223480Z","iopub.execute_input":"2025-01-26T11:54:59.223886Z","iopub.status.idle":"2025-01-26T11:54:59.239920Z","shell.execute_reply.started":"2025-01-26T11:54:59.223842Z","shell.execute_reply":"2025-01-26T11:54:59.238838Z"}},"outputs":[],"execution_count":135},{"cell_type":"code","source":"class ImgEncoder_CNN(nn.Module):\n    def __init__(self, projection_dim=128):\n        super(ImgEncoder_CNN, self).__init__()\n        \n        base_model = models.resnet50(weights=ResNet50_Weights.IMAGENET1K_V1)\n        self.base_model = nn.Sequential(*list(base_model.children())[:-1])\n        \n        # Freezeing the parameters of the base model\n        for param in self.base_model.parameters():\n            param.requires_grad = False  # Corrected attribute name\n        \n        # Define the projection head\n        self.projection_head = ProjectionHead(2048, 256, projection_dim)  # Corrected input_dim\n\n    def forward(self, x):\n    \n        # Extract features from the base model\n        h = self.base_model(x).squeeze()  # Shape: [batch_size, 2048]\n        \n        # Pass through the projection head\n        z = self.projection_head(h)  # Shape: [batch_size, projection_dim]\n        \n        # Normalize the output embeddings\n        return normalize(z, dim=1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:54:59.240999Z","iopub.execute_input":"2025-01-26T11:54:59.241293Z","iopub.status.idle":"2025-01-26T11:54:59.253483Z","shell.execute_reply.started":"2025-01-26T11:54:59.241269Z","shell.execute_reply":"2025-01-26T11:54:59.252396Z"}},"outputs":[],"execution_count":136},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n\n\nmodel = ImgEncoder_CNN(projection_dim=512).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:54:59.254487Z","iopub.execute_input":"2025-01-26T11:54:59.254751Z","iopub.status.idle":"2025-01-26T11:55:00.732145Z","shell.execute_reply.started":"2025-01-26T11:54:59.254727Z","shell.execute_reply":"2025-01-26T11:55:00.730995Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet50-0676ba61.pth\" to /root/.cache/torch/hub/checkpoints/resnet50-0676ba61.pth\n100%|██████████| 97.8M/97.8M [00:00<00:00, 156MB/s]\n","output_type":"stream"}],"execution_count":137},{"cell_type":"code","source":"from torchinfo import summary\n\nsummary(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-26T11:55:00.733186Z","iopub.execute_input":"2025-01-26T11:55:00.733491Z","iopub.status.idle":"2025-01-26T11:55:00.751358Z","shell.execute_reply.started":"2025-01-26T11:55:00.733463Z","shell.execute_reply":"2025-01-26T11:55:00.750375Z"}},"outputs":[{"execution_count":138,"output_type":"execute_result","data":{"text/plain":"======================================================================\nLayer (type:depth-idx)                        Param #\n======================================================================\nImgEncoder_CNN                                --\n├─Sequential: 1-1                             --\n│    └─Conv2d: 2-1                            (9,408)\n│    └─BatchNorm2d: 2-2                       (128)\n│    └─ReLU: 2-3                              --\n│    └─MaxPool2d: 2-4                         --\n│    └─Sequential: 2-5                        --\n│    │    └─Bottleneck: 3-1                   (75,008)\n│    │    └─Bottleneck: 3-2                   (70,400)\n│    │    └─Bottleneck: 3-3                   (70,400)\n│    └─Sequential: 2-6                        --\n│    │    └─Bottleneck: 3-4                   (379,392)\n│    │    └─Bottleneck: 3-5                   (280,064)\n│    │    └─Bottleneck: 3-6                   (280,064)\n│    │    └─Bottleneck: 3-7                   (280,064)\n│    └─Sequential: 2-7                        --\n│    │    └─Bottleneck: 3-8                   (1,512,448)\n│    │    └─Bottleneck: 3-9                   (1,117,184)\n│    │    └─Bottleneck: 3-10                  (1,117,184)\n│    │    └─Bottleneck: 3-11                  (1,117,184)\n│    │    └─Bottleneck: 3-12                  (1,117,184)\n│    │    └─Bottleneck: 3-13                  (1,117,184)\n│    └─Sequential: 2-8                        --\n│    │    └─Bottleneck: 3-14                  (6,039,552)\n│    │    └─Bottleneck: 3-15                  (4,462,592)\n│    │    └─Bottleneck: 3-16                  (4,462,592)\n│    └─AdaptiveAvgPool2d: 2-9                 --\n├─ProjectionHead: 1-2                         --\n│    └─Linear: 2-10                           524,544\n│    └─BatchNorm1d: 2-11                      512\n│    └─ReLU: 2-12                             --\n│    └─Dropout: 2-13                          --\n│    └─Linear: 2-14                           65,792\n│    └─BatchNorm1d: 2-15                      512\n│    └─Linear: 2-16                           131,584\n======================================================================\nTotal params: 24,230,976\nTrainable params: 722,944\nNon-trainable params: 23,508,032\n======================================================================"},"metadata":{}}],"execution_count":138}]}