{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":1462296,"sourceType":"datasetVersion","datasetId":857191},{"sourceId":218487008,"sourceType":"kernelVersion"}],"dockerImageVersionId":30840,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision.models import resnet50, ResNet50_Weights\nfrom torchvision import transforms, models\nfrom ms_coco_data_pipeline import MSCOCODatasetImages\nimport os\nfrom PIL import Image","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dir = \"/kaggle/input/coco-2017-dataset/coco2017/train2017\"\nval_dir = \"/kaggle/input/coco-2017-dataset/coco2017/val2017\"\ntrain_ann_dir = \"/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_train2017.json\"\nval_ann_dir = \"/kaggle/input/coco-2017-dataset/coco2017/annotations/captions_val2017.json\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"preprocessing_transformer = transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomRotation(5),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomResizedCrop(224, scale=(0.9, 1.0)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_dataset = MSCOCODatasetImages(train_dir,train_ann_dir, transform = preprocessing_transformer)\nval_dataset = MSCOCODatasetImages(val_dir,val_ann_dir, transform = preprocessing_transformer)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\nval_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"weights = ResNet50_Weights.DEFAULT\nmodel = resnet50(weights=weights)\nmodel = model.to(device)\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=0.001) ","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from tqdm import tqdm\n\nepochs = 10\n\nfor epoch in range(epochs):\n    model.train()\n    running_loss = 0.0\n    train_loader_tqdm = tqdm(train_loader, desc=f'Epoch [{epoch+1}/{epochs}] Training', leave=False)\n    for images in train_loader_tqdm:\n        images = images.to(device)\n\n        optimizer.zero_grad()\n        outputs = model(images)\n\n        targets = torch.zeros(images.size(0), dtype=torch.long).to(device)\n\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n\n        running_loss += loss.item()\n\n    print(f'Epoch [{epoch+1}/{epochs}], Loss: {running_loss/len(train_loader):.4f}')\n\n    # Validation\n    model.eval()\n    all_predictions = []\n    val_loader_tqdm = tqdm(val_loader, desc=f'Epoch [{epoch+1}/{epochs}] Validation', leave=False)\n    with torch.no_grad():\n        for images in val_loader_tqdm:\n            images = images.to(device)\n            outputs = model(images)\n\n            _, predicted = torch.max(outputs.data, 1)\n            all_predictions.extend(predicted.cpu().numpy())","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}